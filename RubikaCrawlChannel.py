import requests
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import TimeoutException, NoSuchElementException
import time
import re
import pandas as pd
from datetime import datetime, timedelta
from persiantools.jdatetime import JalaliDate
import os
from dotenv import load_dotenv
import schedule
import logging
import traceback

# ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ù„Ø§Ú¯â€ŒÚ¯ÛŒØ±ÛŒ
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler("rubika_crawler.log", encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

load_dotenv(dotenv_path=".env")
# --- ØªÙ†Ø¸ÛŒÙ…Ø§Øª API ---
BASE_API_URL = os.getenv("BASE_API_URL")
LOGIN_URL = f"{BASE_API_URL}/token/"
CHANNEL_API_URL = f"{BASE_API_URL}/rep/channel-code/?platform=4"  # platform=4 for Rubika
POST_API_URL = f"{BASE_API_URL}/rep/posts/"
POSTS_API_URL = f"{BASE_API_URL}/rep/posts/?platform=4&channel={{id}}"

# --- Ø§Ø·Ù„Ø§Ø¹Ø§Øª ÙˆØ±ÙˆØ¯ Ø¨Ù‡ API ---
API_USERNAME = os.getenv("API_USERNAME")
API_PASSWORD = os.getenv("API_PASSWORD")
access_token = None

# --- Ù…ØªØºÛŒØ±Ù‡Ø§ÛŒ Ø³Ø±Ø§Ø³Ø±ÛŒ ---
driver = None
is_logged_in = False
first_channel = True


def setup_driver():
    """ØªÙ†Ø¸ÛŒÙ… Ùˆ Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ù…Ø±ÙˆØ±Ú¯Ø± (ÙÙ‚Ø· ÛŒÚ© Ø¨Ø§Ø±)"""
    global driver
    if driver is None:
        options = webdriver.ChromeOptions()
        options.add_argument("--start-maximized")
        options.add_argument("--disable-dev-shm-usage")
        options.add_argument("--no-sandbox")
        options.add_argument("--disable-blink-features=AutomationControlled")
        options.add_experimental_option("excludeSwitches", ["enable-automation"])
        options.add_experimental_option('useAutomationExtension', False)
        # options.add_argument("--headless")  # Ø¯Ø± ØµÙˆØ±Øª Ù†ÛŒØ§Ø² Ù…ÛŒâ€ŒØªÙˆØ§Ù†ÛŒØ¯ ÙØ¹Ø§Ù„ Ú©Ù†ÛŒØ¯

        try:
            driver = webdriver.Chrome(options=options)
            driver.execute_script("Object.defineProperty(navigator, 'webdriver', {get: () => undefined})")
            logger.info("âœ… Ù…Ø±ÙˆØ±Ú¯Ø± Chrome Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ø´Ø¯.")
            return True
        except Exception as e:
            logger.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ù…Ø±ÙˆØ±Ú¯Ø±: {str(e)}")
            return False
    return True


def manual_login():
    """ÙˆØ±ÙˆØ¯ Ø¯Ø³ØªÛŒ Ø¨Ù‡ Ø±ÙˆØ¨ÛŒÚ©Ø§ (ÙÙ‚Ø· ÛŒÚ© Ø¨Ø§Ø±)"""
    global is_logged_in

    if is_logged_in:
        return True

    logger.info("â³ Ù„Ø·ÙØ§Ù‹ Ø¯Ø³ØªÛŒ ÙˆØ§Ø±Ø¯ Ø­Ø³Ø§Ø¨ Ú©Ø§Ø±Ø¨Ø±ÛŒ Ø±ÙˆØ¨ÛŒÚ©Ø§ Ø®ÙˆØ¯ Ø´ÙˆÛŒØ¯ (30 Ø«Ø§Ù†ÛŒÙ‡ ÙØ±ØµØª Ø¯Ø§Ø±ÛŒØ¯)...")

    # Ø¨Ø§Ø² Ú©Ø±Ø¯Ù† ØµÙØ­Ù‡ Ø§ØµÙ„ÛŒ Ø±ÙˆØ¨ÛŒÚ©Ø§
    driver.get("https://web.rubika.ir/")
    time.sleep(5)

    # Ù…Ù†ØªØ¸Ø± Ù…Ø§Ù†Ø¯Ù† Ø¨Ø±Ø§ÛŒ ÙˆØ±ÙˆØ¯ Ú©Ø§Ø±Ø¨Ø±
    for i in range(30):
        try:
            # Ø¨Ø±Ø±Ø³ÛŒ Ø¢ÛŒØ§ Ú©Ø§Ø±Ø¨Ø± Ù„Ø§Ú¯ÛŒÙ† Ú©Ø±Ø¯Ù‡ (Ø¨Ø§ Ú†Ú© Ú©Ø±Ø¯Ù† ÙˆØ¬ÙˆØ¯ Ø¹Ù†Ø§ØµØ± Ø®Ø§Øµ Ø¨Ø¹Ø¯ Ø§Ø² Ù„Ø§Ú¯ÛŒÙ†)
            WebDriverWait(driver, 2).until(
                EC.presence_of_element_located((By.CSS_SELECTOR, ".sidebar, .chats-list"))
            )
            is_logged_in = True
            logger.info("âœ… ÙˆØ±ÙˆØ¯ Ø¨Ù‡ Ø±ÙˆØ¨ÛŒÚ©Ø§ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯.")
            return True
        except:
            time.sleep(1)

    logger.error("âŒ Ø²Ù…Ø§Ù† ÙˆØ±ÙˆØ¯ Ø¨Ù‡ Ù¾Ø§ÛŒØ§Ù† Ø±Ø³ÛŒØ¯. Ù„Ø·ÙØ§Ù‹ Ø¯Ø± Ø§Ø¬Ø±Ø§ÛŒ Ø¨Ø¹Ø¯ÛŒ ÙˆØ§Ø±Ø¯ Ø´ÙˆÛŒØ¯.")
    return False


def login_to_api():
    """Ù„Ø§Ú¯ÛŒÙ† Ø¨Ù‡ API Ùˆ Ø¯Ø±ÛŒØ§ÙØª ØªÙˆÚ©Ù†"""
    global access_token
    try:
        response = requests.post(LOGIN_URL, data={
            "username": API_USERNAME,
            "password": API_PASSWORD
        })
        response.raise_for_status()
        access_token = response.json().get("access")
        logger.info("âœ… Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø¨Ù‡ API Ù„Ø§Ú¯ÛŒÙ† Ø´Ø¯.")
        return True
    except Exception as e:
        logger.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ù„Ø§Ú¯ÛŒÙ† Ø¨Ù‡ API: {str(e)}")
        return False


def get_channels():
    """Ø¯Ø±ÛŒØ§ÙØª Ù„ÛŒØ³Øª Ú©Ø§Ù†Ø§Ù„â€ŒÙ‡Ø§ Ø§Ø² API"""
    headers = {"Authorization": f"Bearer {access_token}"}
    try:
        response = requests.get(CHANNEL_API_URL, headers=headers)
        response.raise_for_status()
        channels = response.json()
        logger.info(f"âœ… ØªØ¹Ø¯Ø§Ø¯ {len(channels)} Ú©Ø§Ù†Ø§Ù„ Ø¯Ø±ÛŒØ§ÙØª Ø´Ø¯.")
        return channels
    except Exception as e:
        logger.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª Ú©Ø§Ù†Ø§Ù„â€ŒÙ‡Ø§: {str(e)}")
        return []


def get_last_post_date(channel_id):
    """Ø¯Ø±ÛŒØ§ÙØª Ø¢Ø®Ø±ÛŒÙ† ØªØ§Ø±ÛŒØ® Ù¾Ø³Øª ÛŒÚ© Ú©Ø§Ù†Ø§Ù„"""
    headers = {"Authorization": f"Bearer {access_token}"}
    try:
        url = POSTS_API_URL.format(id=channel_id)
        response = requests.get(url, headers=headers)
        response.raise_for_status()
        posts = response.json()
        if posts:
            last_post_date = posts[-1].get("date")
            logger.info(f"Ø¢Ø®Ø±ÛŒÙ† Ù¾Ø³Øª Ú©Ø§Ù†Ø§Ù„ {channel_id} Ø¯Ø± ØªØ§Ø±ÛŒØ® {last_post_date}")
            return last_post_date
        return None
    except Exception as e:
        logger.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª Ø¢Ø®Ø±ÛŒÙ† Ù¾Ø³Øª: {str(e)}")
        return None


def normalize_datetime(dt_str):
    """ÛŒÚ©Ø³Ø§Ù†â€ŒØ³Ø§Ø²ÛŒ ÙØ±Ù…Øª ØªØ§Ø±ÛŒØ®â€ŒÙ‡Ø§ÛŒ Ù…Ø®ØªÙ„Ù Ø¨Ù‡ ÙØ±Ù…Øª Ø§Ø³ØªØ§Ù†Ø¯Ø§Ø±Ø¯"""
    dt_str = re.sub(r'[+-]\d{2}:\d{2}$', '', dt_str)
    dt_str = dt_str.replace('T', ' ')
    dt_str = re.sub(r'\.\d+', '', dt_str)
    return dt_str.strip()


def send_posts_to_api(posts, last_post_date=None):
    """Ø§Ø±Ø³Ø§Ù„ Ù¾Ø³Øªâ€ŒÙ‡Ø§ Ø¨Ù‡ API"""
    headers = {
        "Authorization": f"Bearer {access_token}",
        "Content-Type": "application/json"
    }
    success_count = 0

    if last_post_date is None:
        posts = posts[-50:]

    for post in posts:
        try:
            normalized_post_date = normalize_datetime(post["date"])
            post_datetime = datetime.strptime(normalized_post_date, "%Y-%m-%d %H:%M:%S")

            last_post_datetime = None
            if last_post_date:
                normalized_last_date = normalize_datetime(last_post_date)
                last_post_datetime = datetime.strptime(normalized_last_date, "%Y-%m-%d %H:%M:%S")

            if last_post_datetime is None or post_datetime > last_post_datetime:
                post_to_send = post.copy()
                post_to_send["message_id"] = 0

                logger.info(f"Ø§Ø±Ø³Ø§Ù„ Ù¾Ø³Øª Ø¨Ø§ ØªØ§Ø±ÛŒØ®: {post['date']}")
                response = requests.post(POST_API_URL, json=post_to_send, headers=headers)
                response.raise_for_status()
                success_count += 1
            else:
                logger.info(f"â© Ù¾Ø³Øª Ø¨Ø§ ØªØ§Ø±ÛŒØ® {post['date']} Ù‚Ø¨Ù„Ø§Ù‹ Ø§Ø±Ø³Ø§Ù„ Ø´Ø¯Ù‡ Ø§Ø³Øª (Ø±Ø¯ Ø´Ø¯)")

        except Exception as e:
            logger.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù¾Ø³Øª: {str(e)}")
            continue

    logger.info(f"âœ… {success_count} Ø§Ø² {len(posts)} Ù¾Ø³Øª Ø¬Ø¯ÛŒØ¯ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø§Ø±Ø³Ø§Ù„ Ø´Ø¯.")
    return success_count > 0


def persian_date_to_gregorian(persian_date_str):
    """ØªØ¨Ø¯ÛŒÙ„ ØªØ§Ø±ÛŒØ® Ø´Ù…Ø³ÛŒ Ø¨Ù‡ Ù…ÛŒÙ„Ø§Ø¯ÛŒ"""
    try:
        persian_date_str = persian_date_str.split('ØŒ ')[1].strip()
        parts = persian_date_str.split(' ')
        day = int(parts[0])
        month_name = parts[1]
        year = int(parts[2])

        month_names = {
            'ÙØ±ÙˆØ±Ø¯ÛŒÙ†': 1, 'Ø§Ø±Ø¯ÛŒØ¨Ù‡Ø´Øª': 2, 'Ø®Ø±Ø¯Ø§Ø¯': 3, 'ØªÛŒØ±': 4, 'Ù…Ø±Ø¯Ø§Ø¯': 5,
            'Ø´Ù‡Ø±ÛŒÙˆØ±': 6, 'Ù…Ù‡Ø±': 7, 'Ø¢Ø¨Ø§Ù†': 8, 'Ø¢Ø°Ø±': 9, 'Ø¯ÛŒ': 10,
            'Ø¨Ù‡Ù…Ù†': 11, 'Ø§Ø³ÙÙ†Ø¯': 12
        }
        month = month_names.get(month_name, 1)

        jalali_date = JalaliDate(year, month, day)
        return jalali_date.to_gregorian().strftime('%Y-%m-%d')
    except:
        return None


def extract_hashtags(text):
    """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù‡Ø´ØªÚ¯â€ŒÙ‡Ø§ Ø§Ø² Ù…ØªÙ†"""
    if not text:
        return ""
    clean_text = re.sub(r'<[^>]+>', '', text)
    clean_text = re.sub(r'https?://\S+|www\.\S+', '', clean_text)
    hashtags = re.findall(r'(#\w[^\s#<>ØŒ:;.!?\u200c]*)', clean_text)
    valid_hashtags = []
    for tag in hashtags:
        clean_tag = re.sub(r'[^\w\u0600-\u06FF\-_#]+$', '', tag)
        if len(clean_tag) > 1:
            valid_hashtags.append(clean_tag)
    return ' '.join(valid_hashtags) if valid_hashtags else ""


def clean_post_text(raw_html):
    """Ù¾Ø§Ú©â€ŒØ³Ø§Ø²ÛŒ Ù…ØªÙ† Ù¾Ø³Øª"""
    if not raw_html:
        return "(Ø¨Ø¯ÙˆÙ† Ù…ØªÙ†)"
    cleaned_text = re.sub(r'<div class="reactions reactions-block">.*?</div>', '', raw_html, flags=re.DOTALL)
    cleaned_text = re.sub(r'<a\b[^>]*>(.*?)</a>', '', cleaned_text)
    cleaned_text = re.sub(r'<div[^>]*>|</div>', '', cleaned_text)
    cleaned_text = re.sub(r'<span[^>]*>.*?</span>', '', cleaned_text)
    cleaned_text = re.sub(r':[a-z_]+:', '', cleaned_text)
    cleaned_text = re.sub(r'<[^>]+>', '', cleaned_text)
    cleaned_text = re.sub(r'https?://\S+|www\.\S+', '', cleaned_text)
    cleaned_text = re.sub(r'@\w+', '', cleaned_text)
    cleaned_text = re.sub(r'[\u200c\u200e\u200f]', '', cleaned_text)
    cleaned_text = re.sub(r'[^\w\s\u0600-\u06FF\uFB8A\u067E\u0686\u06AF\u200C\u200F.,ØŒ:;!?Ù€]', '', cleaned_text)
    cleaned_text = re.sub(r'\s+', ' ', cleaned_text).strip()
    patterns = [
        r':point_down:.*',
        r':point_up_2:.*',
        r':bangbang:.*',
        r':rotating_light:.*'
    ]
    for pattern in patterns:
        cleaned_text = re.sub(pattern, '', cleaned_text)
    cleaned_text = re.sub(r'\n\s*\n', '\n', cleaned_text)
    return cleaned_text.strip() or "(Ø¨Ø¯ÙˆÙ† Ù…ØªÙ†)"


def process_channel(channel):
    """Ù¾Ø±Ø¯Ø§Ø²Ø´ ÛŒÚ© Ú©Ø§Ù†Ø§Ù„"""
    global first_channel

    channel_id = channel.get("channel_id")
    channel_name = channel.get("name", "Ø¨Ø¯ÙˆÙ† Ù†Ø§Ù…")
    my_id = channel.get("id")
    logger.info(f"\nğŸ” Ø´Ø±ÙˆØ¹ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ú©Ø§Ù†Ø§Ù„: {channel_name} (ID: {channel_id})")

    # Ø¯Ø±ÛŒØ§ÙØª Ø¢Ø®Ø±ÛŒÙ† ØªØ§Ø±ÛŒØ® Ù¾Ø³Øª
    last_post_date = get_last_post_date(my_id)

    # Ø¨Ø§Ø² Ú©Ø±Ø¯Ù† ØµÙØ­Ù‡ Ú©Ø§Ù†Ø§Ù„
    url = f"https://web.rubika.ir/#c={channel_id}"
    logger.info(f"ğŸŒ Ø¯Ø± Ø­Ø§Ù„ Ø¨Ø§Ø² Ú©Ø±Ø¯Ù†: {url}")

    # Ø¨Ø§Ø²Ú¯Ø´Øª Ø¨Ù‡ ØµÙØ­Ù‡ Ø§ØµÙ„ÛŒ Ù‚Ø¨Ù„ Ø§Ø² Ø±ÙØªÙ† Ø¨Ù‡ Ú©Ø§Ù†Ø§Ù„
    driver.get("https://web.rubika.ir/")
    time.sleep(2)

    # Ø±ÙØªÙ† Ø¨Ù‡ Ú©Ø§Ù†Ø§Ù„ Ù…ÙˆØ±Ø¯ Ù†Ø¸Ø±
    driver.get(url)
    time.sleep(5)

    # Ø¨Ø±Ø±Ø³ÛŒ Ø§ÛŒÙ†Ú©Ù‡ Ø¢ÛŒØ§ Ø¯Ø± ØµÙØ­Ù‡ ØµØ­ÛŒØ­ Ù‡Ø³ØªÛŒÙ…
    current_url = driver.current_url
    logger.info(f"Ø¢Ø¯Ø±Ø³ ÙØ¹Ù„ÛŒ: {current_url}")

    if f"c={channel_id}" not in current_url:
        logger.info(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ú©Ø§Ù†Ø§Ù„ {channel_id}")
        logger.info("ØªÙ„Ø§Ø´ Ù…Ø¬Ø¯Ø¯...")
        driver.get(url)
        time.sleep(10)

        if f"c={channel_id}" not in driver.current_url:
            logger.info(f"âŒâŒ Ø®Ø·Ø§ÛŒ Ø¬Ø¯ÛŒ: Ù†ØªÙˆØ§Ù†Ø³ØªÛŒÙ… Ø¨Ù‡ Ú©Ø§Ù†Ø§Ù„ {channel_id} Ø¨Ø±ÙˆÛŒÙ…. Ø±Ø¯ Ø´Ø¯Ù† Ø§Ø² Ø§ÛŒÙ† Ú©Ø§Ù†Ø§Ù„...")
            return False

    # Ù¾ÛŒØ¯Ø§ Ú©Ø±Ø¯Ù† Ú©Ø§Ù†ØªÛŒÙ†Ø± Ù¾ÛŒØ§Ù…â€ŒÙ‡Ø§
    logger.info("ğŸ” Ø¯Ø± Ø­Ø§Ù„ ÛŒØ§ÙØªÙ† Ú©Ø§Ù†ØªÛŒÙ†Ø± Ø§Ø³Ú©Ø±ÙˆÙ„...")
    try:
        chat_container = WebDriverWait(driver, 30).until(
            EC.presence_of_element_located((By.CSS_SELECTOR, ".scrollable.scrollable-y")))
        logger.info("âœ… Ú©Ø§Ù†ØªÛŒÙ†Ø± Ø§Ø³Ú©Ø±ÙˆÙ„ Ù¾ÛŒØ¯Ø§ Ø´Ø¯.")
    except TimeoutException:
        logger.error("âŒ Ú©Ø§Ù†ØªÛŒÙ†Ø± Ø§Ø³Ú©Ø±ÙˆÙ„ Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯.")
        return False

    # Ù‚Ø±Ø§Ø± Ø¯Ø§Ø¯Ù† Ù…ÙˆØ³ Ø¯Ø± Ù…ÙˆÙ‚Ø¹ÛŒØª Ù…Ù†Ø§Ø³Ø¨
    logger.info("\nâš ï¸ Ù‚Ø±Ø§Ø± Ø¯Ø§Ø¯Ù† Ù…ÙˆØ³ Ø¯Ø± ÙˆØ³Ø· Ú©Ø§Ù†ØªÛŒÙ†Ø±...")
    try:
        first_message = chat_container.find_element(By.CSS_SELECTOR, "[data-msg-id]")
        driver.execute_script("arguments[0].scrollIntoView({block: 'center'});", first_message)
        time.sleep(2)
    except:
        logger.warning("âš ï¸ Ù†ØªÙˆØ§Ù†Ø³ØªÙ… Ù¾ÛŒØ§Ù…ÛŒ Ø¨Ø±Ø§ÛŒ Ù‚Ø±Ø§Ø± Ø¯Ø§Ø¯Ù† Ù…ÙˆØ³ Ù¾ÛŒØ¯Ø§ Ú©Ù†Ù…ØŒ Ø§Ø¯Ø§Ù…Ù‡ Ù…ÛŒâ€ŒØ¯Ù‡Ù…...")

    # Ø´Ø±ÙˆØ¹ Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ Ù¾ÛŒØ§Ù…â€ŒÙ‡Ø§
    seen_msg_ids = set()
    messages_data = []
    scroll_count = 0
    current_date = datetime.now().date()
    last_processed_date = None
    reached_last_post = False

    logger.info("ğŸ”„ Ø´Ø±ÙˆØ¹ Ø§Ø³Ú©Ø±ÙˆÙ„ Ø¨Ù‡ Ø¨Ø§Ù„Ø§ Ø¨Ø±Ø§ÛŒ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù¾ÛŒØ§Ù…â€ŒÙ‡Ø§...")

    while not reached_last_post:
        scroll_count += 1
        logger.info(f"\n--- Ø§Ø³Ú©Ø±ÙˆÙ„ Ø´Ù…Ø§Ø±Ù‡ {scroll_count} ---")

        prev_scroll_top = driver.execute_script("return arguments[0].scrollTop;", chat_container)
        driver.execute_script("arguments[0].scrollTop = arguments[0].scrollTop - 500;", chat_container)
        time.sleep(2)

        try:
            new_elements = driver.find_elements(By.CSS_SELECTOR, "[data-msg-id], .bubble.service.is-date")
            new_messages_found = False

            for el in new_elements:
                if 'is-date' in el.get_attribute('class'):
                    try:
                        date_text = el.find_element(By.CSS_SELECTOR, 'span').text
                        gregorian_date = persian_date_to_gregorian(date_text)
                        if gregorian_date:
                            current_date = datetime.strptime(gregorian_date, '%Y-%m-%d').date()
                            last_processed_date = current_date

                            if last_post_date and current_date <= datetime.strptime(last_post_date, '%Y-%m-%d').date():
                                logger.info(f"âœ… Ø¨Ù‡ ØªØ§Ø±ÛŒØ® Ø¢Ø®Ø±ÛŒÙ† Ù¾Ø³Øª ({last_post_date}) Ø±Ø³ÛŒØ¯ÛŒÙ….")
                                reached_last_post = True
                                break
                    except:
                        continue
                else:
                    msg_id = el.get_attribute("data-msg-id")
                    if msg_id and msg_id not in seen_msg_ids:
                        seen_msg_ids.add(msg_id)
                        new_messages_found = True

            if reached_last_post:
                break

        except:
            new_messages_found = False

        current_scroll_top = driver.execute_script("return arguments[0].scrollTop;", chat_container)

        if current_scroll_top == prev_scroll_top:
            if not new_messages_found:
                logger.info("â³ Ø§Ø³Ú©Ø±ÙˆÙ„ ØªØºÛŒÛŒØ±ÛŒ Ù†Ú©Ø±Ø¯. Ø¨Ø±Ø±Ø³ÛŒ Ù†Ù‡Ø§ÛŒÛŒ...")
                time.sleep(3)

                driver.execute_script("arguments[0].scrollTop = arguments[0].scrollTop - 100;", chat_container)
                time.sleep(2)

                current_scroll_top = driver.execute_script("return arguments[0].scrollTop;", chat_container)
                if current_scroll_top == prev_scroll_top:
                    logger.info("â¸ï¸ Ø¨Ù‡ Ù†Ø¸Ø± Ù…ÛŒâ€ŒØ±Ø³Ø¯ Ø¨Ù‡ Ø§Ø¨ØªØ¯Ø§ÛŒ ØªØ§Ø±ÛŒØ®Ú†Ù‡ Ø±Ø³ÛŒØ¯Ù‡â€ŒØ§ÛŒÙ….")
                    break
            else:
                logger.info("ğŸ” Ù¾ÛŒØ§Ù…â€ŒÙ‡Ø§ÛŒ Ø¬Ø¯ÛŒØ¯ Ù¾ÛŒØ¯Ø§ Ø´Ø¯ØŒ Ø§Ø¯Ø§Ù…Ù‡ Ø§Ø³Ú©Ø±ÙˆÙ„...")
        else:
            logger.info(f"ğŸ“Š Ù…Ø¬Ù…ÙˆØ¹ Ù¾ÛŒØ§Ù…â€ŒÙ‡Ø§ÛŒ ÛŒÚ©ØªØ§: {len(seen_msg_ids)}")

    # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù†Ù‡Ø§ÛŒÛŒ Ù¾ÛŒØ§Ù…â€ŒÙ‡Ø§
    logger.info("\nğŸ“¥ Ø¯Ø± Ø­Ø§Ù„ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù†Ø§Ø²ÛŒ Ù¾ÛŒØ§Ù…â€ŒÙ‡Ø§...")
    all_elements = driver.find_elements(By.CSS_SELECTOR, ".bubbles-group[data-msg-id], .bubble.service.is-date")

    current_date = datetime.now().date()
    last_processed_date = None

    for elem in all_elements:
        try:
            if 'is-date' in elem.get_attribute('class'):
                try:
                    date_text = elem.find_element(By.CSS_SELECTOR, 'span').text
                    gregorian_date = persian_date_to_gregorian(date_text)
                    if gregorian_date:
                        current_date = datetime.strptime(gregorian_date, '%Y-%m-%d').date()
                        last_processed_date = current_date
                except:
                    continue
            else:
                msg_id = elem.get_attribute("data-msg-id")
                if not msg_id:
                    continue

                raw_html = ""
                try:
                    try:
                        text_elem = elem.find_element(By.CSS_SELECTOR, "[rb-message-text] div[rb-copyable]")
                        raw_html = text_elem.get_attribute("innerHTML")
                    except:
                        content_div = elem.find_element(By.CSS_SELECTOR, ".message > div, .message-wrapper > div")
                        raw_html = content_div.get_attribute("innerHTML")
                except:
                    pass

                caption = clean_post_text(raw_html)
                hashtags = extract_hashtags(raw_html)

                forward_from_chat_title = None
                try:
                    forward_elem = elem.find_element(By.CSS_SELECTOR, ".im_message_fwd_author")
                    forward_from_chat_title = forward_elem.text.strip()
                except:
                    pass

                has_media = False
                try:
                    media_elem = elem.find_element(By.CSS_SELECTOR, ".media-photo")
                    has_media = True
                except:
                    pass

                views = 0
                time_str = "00:00"
                try:
                    time_elem = elem.find_element(By.CSS_SELECTOR, "span[rb-message-time]")
                    inner_html = ""
                    try:
                        inner_div = time_elem.find_element(By.CSS_SELECTOR, "div.inner.rbico")
                        inner_html = inner_div.get_attribute("innerHTML")
                    except:
                        inner_html = time_elem.get_attribute("innerHTML")

                    views_match = re.search(r'(\d[\d.,]*)\s*<!-{2,}>\s*<!-{2,}>\s*<i[^>]+rbico-channelviews',
                                            inner_html)
                    if not views_match:
                        views_match = re.search(r'(\d[\d.,]*)\s*<i[^>]+rbico-channelviews', inner_html)
                    if views_match:
                        v = views_match.group(1).replace('M', '000000').replace('K', '000').replace('.', '')
                        views = int(v) if v.isdigit() else 0

                    time_match = re.search(r'<span>(\d{1,2}:\d{2})</span>', inner_html)
                    time_str = time_match.group(1) if time_match else "00:00"
                except:
                    pass

                message_date = current_date

                if last_processed_date is None and current_date == datetime.now().date():
                    message_date = current_date - timedelta(days=1)

                try:
                    hour, minute = map(int, time_str.split(':'))
                    datetime_combined = datetime.combine(message_date, datetime.min.time()).replace(hour=hour,
                                                                                                    minute=minute)
                    datetime_str = datetime_combined.strftime('%Y-%m-%d %H:%M:%S')
                except:
                    datetime_str = f"{message_date.strftime('%Y-%m-%d')} 00:00:00"

                if msg_id not in [d["message_id"] for d in messages_data]:
                    messages_data.append({
                        "message_id": msg_id,
                        "date": datetime_str,
                        "post_text": caption,
                        "hashtags": hashtags,
                        "views": views,
                        "sender_name": channel_name,
                        "sender_username": channel_id,
                        "chat_id": channel_id,
                        "chat_type": "channel",
                        "has_media": has_media,
                        "forward_from_chat_title": forward_from_chat_title,
                        "collected_at": datetime_combined.strftime('%Y-%m-%d'),
                        "author": 1,
                        "channel": my_id
                    })

        except Exception as e:
            logger.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù¾ÛŒØ§Ù…: {str(e)}")
            continue

    # Ø§Ø±Ø³Ø§Ù„ Ù¾Ø³Øªâ€ŒÙ‡Ø§ Ø¨Ù‡ API
    if messages_data:
        logger.info(f"\nğŸ“¤ Ø¯Ø± Ø­Ø§Ù„ Ø§Ø±Ø³Ø§Ù„ Ù¾Ø³Øªâ€ŒÙ‡Ø§ÛŒ Ø¬Ø¯ÛŒØ¯ Ø¨Ù‡ API...")
        if send_posts_to_api(messages_data, last_post_date):
            logger.info(f"âœ… Ù¾Ø³Øªâ€ŒÙ‡Ø§ÛŒ Ø¬Ø¯ÛŒØ¯ Ú©Ø§Ù†Ø§Ù„ {channel_name} Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø§Ø±Ø³Ø§Ù„ Ø´Ø¯Ù†Ø¯.")
            return True
        else:
            logger.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø§Ø±Ø³Ø§Ù„ Ù¾Ø³Øªâ€ŒÙ‡Ø§ÛŒ Ú©Ø§Ù†Ø§Ù„ {channel_name}.")
            return False
    else:
        logger.info("â„¹ï¸ Ù‡ÛŒÚ† Ù¾Ø³Øª Ø¬Ø¯ÛŒØ¯ÛŒ Ø¨Ø±Ø§ÛŒ Ø§Ø±Ø³Ø§Ù„ Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯.")
        return True


def run_crawler():
    """ØªØ§Ø¨Ø¹ Ø§ØµÙ„ÛŒ Ø§Ø¬Ø±Ø§ÛŒ Ú©Ø±Ø§ÙˆÙ„Ø±"""
    global first_channel

    logger.info("ğŸš€ Ø´Ø±ÙˆØ¹ Ø§Ø¬Ø±Ø§ÛŒ Ú©Ø±Ø§ÙˆÙ„Ø±...")

    # Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ø¯Ø±Ø§ÛŒÙˆØ± (ÙÙ‚Ø· Ø§Ú¯Ø± ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ø¯)
    if not setup_driver():
        return False

    # ÙˆØ±ÙˆØ¯ Ø¯Ø³ØªÛŒ (ÙÙ‚Ø· ÛŒÚ© Ø¨Ø§Ø±)
    if not is_logged_in and not manual_login():
        return False

    # Ù„Ø§Ú¯ÛŒÙ† Ø¨Ù‡ API
    if not login_to_api():
        return False

    # Ø¯Ø±ÛŒØ§ÙØª Ú©Ø§Ù†Ø§Ù„â€ŒÙ‡Ø§
    channels = get_channels()
    if not channels:
        return False

    # Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù‡Ø± Ú©Ø§Ù†Ø§Ù„
    success_count = 0

    for channel in channels:
        try:
            if process_channel(channel):
                success_count += 1
        except Exception as e:
            logger.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ Ú©Ø§Ù†Ø§Ù„ {channel.get('name')}: {str(e)}")
            logger.error(traceback.format_exc())

    logger.info(f"ğŸ”š Ø§Ø¬Ø±Ø§ÛŒ Ú©Ø±Ø§ÙˆÙ„Ø± Ú©Ø§Ù…Ù„ Ø´Ø¯. {success_count} Ø§Ø² {len(channels)} Ú©Ø§Ù†Ø§Ù„ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø´Ø¯Ù†Ø¯.")
    return success_count > 0


def cleanup():
    """ØªÙ…ÛŒØ²Ú©Ø§Ø±ÛŒ Ù‡Ù†Ú¯Ø§Ù… Ø®Ø±ÙˆØ¬"""
    global driver
    if driver:
        try:
            driver.quit()
            logger.info("âœ… Ù…Ø±ÙˆØ±Ú¯Ø± Ø¨Ø³ØªÙ‡ Ø´Ø¯.")
        except:
            pass


if __name__ == "__main__":
    try:
        # Ø§ÙˆÙ„ÛŒÙ† Ø§Ø¬Ø±Ø§ Ø±Ø§ ÙÙˆØ±ÛŒ Ø§Ù†Ø¬Ø§Ù… Ø¨Ø¯Ù‡
        run_crawler()

        # Ø¨Ø±Ù†Ø§Ù…Ù‡â€ŒØ±ÛŒØ²ÛŒ Ø¨Ø±Ø§ÛŒ Ø§Ø¬Ø±Ø§ÛŒ Ø¨Ø¹Ø¯ÛŒ Ù‡Ø± 3 Ø³Ø§Ø¹Øª
        schedule.every(3).hours.do(run_crawler)

        logger.info("â° Ø¨Ø±Ù†Ø§Ù…Ù‡ Ø¨Ù‡ ØµÙˆØ±Øª Ø®ÙˆØ¯Ú©Ø§Ø± Ù‡Ø± 3 Ø³Ø§Ø¹Øª Ø§Ø¬Ø±Ø§ Ù…ÛŒâ€ŒØ´ÙˆØ¯...")

        while True:
            schedule.run_pending()
            time.sleep(60)  # Ù‡Ø± Ø¯Ù‚ÛŒÙ‚Ù‡ Ú†Ú© Ù…ÛŒâ€ŒÚ©Ù†Ø¯

    except KeyboardInterrupt:
        logger.info("â¹ï¸ Ø¯Ø±ÛŒØ§ÙØª Ø³ÛŒÚ¯Ù†Ø§Ù„ ØªÙˆÙ‚Ù...")
    except Exception as e:
        logger.error(f"âŒ Ø®Ø·Ø§ÛŒ ØºÛŒØ±Ù…Ù†ØªØ¸Ø±Ù‡: {str(e)}")
        logger.error(traceback.format_exc())
    finally:
        cleanup()